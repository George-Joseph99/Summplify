{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "56be9705",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "import numpy as np\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from itertools import islice\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1bafbdcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\moham\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "84d568dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(article):\n",
    "    lines = article.split(\".\")   # splits the whole article into lines\n",
    "    stemmer = PorterStemmer()\n",
    "    stopwords_english = stopwords.words('english')\n",
    "    article_preprocessed = []    # list that contains the main sentences after being preprocessed \n",
    "    for line in lines:\n",
    "        line_preprocessed = []\n",
    "        words_in_line = line.split()\n",
    "        for word in words_in_line:\n",
    "            if (word not in stopwords_english and word not in string.punctuation):   # make sure word is not a stop word\n",
    "                                                                                     # and not a punctuation \n",
    "                word_stemmed = stemmer.stem(word)  \n",
    "                line_preprocessed.append(word_stemmed)\n",
    "        article_preprocessed.append(line_preprocessed)\n",
    "    return article_preprocessed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "e46cfebe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[\"'alcohol'\", 'taken', 'almost', 'cool', 'cold', 'climates,', 'much', 'less', 'extent', 'hot', 'one'], ['thus,', 'taken', 'peopl', 'live', 'himalaya', 'mountains,', 'nearli', 'much', 'live', 'plain', 'india'], ['alcohol', 'necessari', 'way', 'anybodi'], ['the', 'regular', 'use', 'alcohol,', 'even', 'small', 'quantities,', 'tend', 'caus', 'mischief', 'mani', 'way', 'variou', 'organ', 'bodi'], ['it', 'affect', 'liver,', 'weaken', 'mental', 'powers,', 'lessen', 'gener', 'energi', 'bodi'], ['in', 'addition,', 'damag', 'central', 'nervou', 'system', 'peripher', 'nervou', 'system', 'occur', 'chronic', 'alcohol', 'abus'], []]\n"
     ]
    }
   ],
   "source": [
    "with open(\"article_2.txt\", \"r\", encoding=\"utf8\") as file:\n",
    "    contents = file.read()\n",
    "    article_preprocessed = preprocessing(contents)\n",
    "    print(article_preprocessed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "c60a9372",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Alcohol' is taken in almost all cool and cold climates, and to a very much less extent in hot ones. Thus, it is taken by people who live in the Himalaya Mountains, but not nearly so much by those who live in the plains of India. Alcohol is not necessary in any way to anybody. The regular use of alcohol, even in small quantities, tends to cause mischief in many ways to various organs of the body. It affects the liver, it weakens the mental powers, and lessens the general energy of the body. In addition, damage to the central nervous system and peripheral nervous system can occur from chronic alcohol abuse.\n"
     ]
    }
   ],
   "source": [
    "print(contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "3714a510",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_list_to_string(content):\n",
    "    content_modified = []   # list of strings\n",
    "    for line in content:\n",
    "        line_as_string = \" \".join(line)\n",
    "        content_modified.append(line_as_string)\n",
    "    return content_modified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "925e25cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_TF_IDF(content):\n",
    "    \n",
    "    vectorizer = TfidfVectorizer()   # Create a TfidfVectorizer object\n",
    "    vectorizer.fit(content)   # Fit the vectorizer to the documents\n",
    "    feature_names = vectorizer.get_feature_names()\n",
    "\n",
    "#     print(\"Feature names:\")   # Print the feature names\n",
    "#     print(feature_names)   \n",
    "\n",
    "    tfidf_matrix = vectorizer.transform(content)   # Transform the documents into a TF-IDF matrix\n",
    "    np.set_printoptions(threshold=np.inf)\n",
    "#     print(\"TF-IDF matrix:\")   # Print the TF-IDF matrix\n",
    "#     print(tfidf_matrix.toarray())\n",
    "    return tfidf_matrix.toarray()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "9c293a15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.        , 0.19720761, 0.32013214,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.32013214, 0.32013214, 0.32013214, 0.        , 0.        ,\n",
       "        0.        , 0.32013214, 0.        , 0.        , 0.32013214,\n",
       "        0.        , 0.        , 0.        , 0.32013214, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.26573717, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.32013214, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.26573717, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.28423219, 0.        ,\n",
       "        0.        , 0.28423219, 0.        , 0.        , 0.        ,\n",
       "        0.56846439, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.28423219, 0.23593713, 0.28423219, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.28423219, 0.        ,\n",
       "        0.28423219, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.23593713, 0.        , 0.        , 0.28423219,\n",
       "        0.        , 0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.35166548, 0.        ,\n",
       "        0.57086754, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.57086754, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.47386908, 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.1660824 , 0.        ,\n",
       "        0.        , 0.22379596, 0.26960579, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.26960579, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.26960579, 0.        , 0.26960579,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.26960579, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.26960579, 0.26960579, 0.26960579,\n",
       "        0.        , 0.        , 0.26960579, 0.26960579, 0.        ,\n",
       "        0.26960579, 0.26960579, 0.22379596, 0.        ],\n",
       "       [0.        , 0.        , 0.32126215, 0.        , 0.        ,\n",
       "        0.        , 0.26667518, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.32126215,\n",
       "        0.        , 0.        , 0.32126215, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.32126215, 0.        , 0.32126215,\n",
       "        0.        , 0.32126215, 0.        , 0.32126215, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.32126215, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.32126215],\n",
       "       [0.24708703, 0.24708703, 0.        , 0.1522104 , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.24708703, 0.24708703,\n",
       "        0.        , 0.        , 0.        , 0.24708703, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.24708703, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.49417406,\n",
       "        0.24708703, 0.        , 0.        , 0.        , 0.24708703,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.49417406, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        ]])"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "article_modified = convert_list_to_string(article_preprocessed)\n",
    "calculate_TF_IDF(article_modified)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "28a6ceff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_each_sentence_score(tf_idf_matrix):\n",
    "    score_dict = {}   # dictionary that stores keys as summation of tf_idf scores for all word in current line \n",
    "                      # and values of dictionary as index of the line in the article\n",
    "    for index, line in enumerate(tf_idf_matrix):\n",
    "#         print(line)\n",
    "#         print('at')\n",
    "#         print(index)\n",
    "        score = np.sum(line)\n",
    "        score_dict[score] = index\n",
    "        \n",
    "    sorted_keys = sorted(score_dict.items(), reverse=True)   # sort the dictionary by keys in the descending order\n",
    "    score_dict_reversed = dict(sorted_keys)\n",
    "\n",
    "#     print(score_dict_reversed)\n",
    "    return score_dict_reversed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "3bb039f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summary_generation(article, score_dict_reversed, number_of_sentences):\n",
    "    lines = article.split(\".\")   # list contains strings, where these strings are original lines\n",
    "    \n",
    "    score_dict = dict(islice(score_dict_reversed.items(), number_of_sentences))   # select only certain number of lines\n",
    "                                                                                  # to be displayed \n",
    "        \n",
    "    sort_data = sorted(score_dict.items(), key=lambda x: x[1])   # sort the dictionary by value (index of lines) in\n",
    "                                                                 # the ascending order to display lines ordered as the \n",
    "                                                                 # original article \n",
    "    score_dict_ascending = dict(sort_data)\n",
    "    print(score_dict_ascending)\n",
    "    print(score_dict_reversed)\n",
    "    output_list = []\n",
    "    for key in score_dict_ascending:\n",
    "        output_list.append(lines[score_dict_ascending[key]])\n",
    "            \n",
    "    output_string = \".\".join(output_list)\n",
    "    output_string += \".\"\n",
    "    return output_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "1319f96d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{3.289739028647383: 0, 3.8489437778305033: 3, 3.1580345719945706: 4}\n",
      "{3.8489437778305033: 3, 3.289739028647383: 0, 3.1580345719945706: 4, 3.117254743580706: 5, 3.0299640067036613: 1, 1.967269629670797: 2, 0.0: 6}\n",
      "'Alcohol' is taken in almost all cool and cold climates, and to a very much less extent in hot ones. The regular use of alcohol, even in small quantities, tends to cause mischief in many ways to various organs of the body. It affects the liver, it weakens the mental powers, and lessens the general energy of the body.\n"
     ]
    }
   ],
   "source": [
    "article_modified = convert_list_to_string(article_preprocessed)\n",
    "tf_idf_matrix = calculate_TF_IDF(article_modified)\n",
    "dict_scores = calculate_each_sentence_score(tf_idf_matrix)\n",
    "output = summary_generation(contents, dict_scores, 3)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "f91227cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_length(content):\n",
    "    max_length = 0\n",
    "    for sentence in content:\n",
    "        print(sentence)\n",
    "        if len(sentence) > max_length:\n",
    "            max_length = len(sentence)\n",
    "            \n",
    "    sentence_length_feature = []\n",
    "    for sentence in content:\n",
    "        sentence_length_feature.append(len(sentence) / max_length)\n",
    "    return sentence_length_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "6271fdad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"'alcohol'\", 'taken', 'almost', 'cool', 'cold', 'climates,', 'much', 'less', 'extent', 'hot', 'one']\n",
      "['thus,', 'taken', 'peopl', 'live', 'himalaya', 'mountains,', 'nearli', 'much', 'live', 'plain', 'india']\n",
      "['alcohol', 'necessari', 'way', 'anybodi']\n",
      "['the', 'regular', 'use', 'alcohol,', 'even', 'small', 'quantities,', 'tend', 'caus', 'mischief', 'mani', 'way', 'variou', 'organ', 'bodi']\n",
      "['it', 'affect', 'liver,', 'weaken', 'mental', 'powers,', 'lessen', 'gener', 'energi', 'bodi']\n",
      "['in', 'addition,', 'damag', 'central', 'nervou', 'system', 'peripher', 'nervou', 'system', 'occur', 'chronic', 'alcohol', 'abus']\n",
      "[]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.7333333333333333,\n",
       " 0.7333333333333333,\n",
       " 0.26666666666666666,\n",
       " 1.0,\n",
       " 0.6666666666666666,\n",
       " 0.8666666666666667,\n",
       " 0.0]"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_length(article_preprocessed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "f7f3e6b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Claxton hunting first major medal.\n",
      "\n",
      "British hurdler Sarah Claxton is confident she can win her first major medal at next month's European Indoor Championships in Madrid.\n",
      "\n",
      "The 25-year-old has already smashed the British record over 60m hurdles twice this season, setting a new mark of 7.96 seconds to win the AAAs title. \"I am quite confident,\" said Claxton. \"But I take each race as it comes. \"As long as I keep up my training but not do too much I think there is a chance of a medal.\" Claxton has won the national 60m hurdles title for the past three years but has struggled to translate her domestic success to the international stage. Now, the Scotland-born athlete owns the equal fifth-fastest time in the world this year. And at last week's Birmingham Grand Prix, Claxton left European medal favourite Russian Irina Shevchenko trailing in sixth spot.\n",
      "\n",
      "For the first time, Claxton has only been preparing for a campaign over the hurdles - which could explain her leap in form. In previous seasons, the 25-year-old also contested the long jump but since moving from Colchester to London she has re-focused her attentions. Claxton will see if her new training regime pays dividends at the European Indoors which take place on 5-6 March.\n",
      "\n",
      "For the first time, Claxton has only been preparing for a campaign over the hurdles - which could explain her leap in form.Claxton has won the national 60m hurdles title for the past three years but has struggled to translate her domestic success to the international stage.British hurdler Sarah Claxton is confident she can win her first major medal at next month's European Indoor Championships in Madrid.Claxton will see if her new training regime pays dividends at the European Indoors which take place on 5-6 March.\"I am quite confident,\" said Claxton.\n"
     ]
    }
   ],
   "source": [
    "with open(\"001_original.txt\", \"r\", encoding=\"utf8\") as file:\n",
    "    original = file.read()\n",
    "    article_preprocessed = preprocessing(original)\n",
    "    print(original)\n",
    "\n",
    "with open(\"001_summarized.txt\", \"r\", encoding=\"utf8\") as file:\n",
    "    summarized = file.read()\n",
    "    print(summarized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "88e1baca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_Y_labels(original, summarized):\n",
    "    Y_list = []\n",
    "    original_list = re.split(r\"\\n\\n|\\.\", original)\n",
    "    original_list_removed_empty = [x for x in original_list if x.strip()]   # removes empty elements\n",
    "    original_list_no_quotation = [x.replace('\"', '') for x in original_list_removed_empty]\n",
    "    original_list_no_first_space = [x.lstrip() for x in original_list_no_quotation]\n",
    "    \n",
    "    summarized_list = summarized.replace('\"', '')\n",
    "    summarized_list = summarized.split(\".\")\n",
    "    summarized_list_removed_empty = [x for x in summarized_list if x.strip()]   # removes empty elements\n",
    "    summarized_list_no_quotation = [x.replace('\"', '') for x in summarized_list_removed_empty]\n",
    "    summarized_list_no_first_space = [x.lstrip() for x in summarized_list_no_quotation]\n",
    "    \n",
    "    print(original_list_no_first_space)\n",
    "    print(summarized_list_no_first_space)\n",
    "    \n",
    "    print(len(original_list_no_first_space))\n",
    "    print(len(summarized_list_no_first_space))\n",
    "    for sentences in original_list_no_first_space:\n",
    "        if sentences in summarized_list_no_first_space:\n",
    "            Y_list.append(1)\n",
    "            print(sentences)\n",
    "            \n",
    "        else:\n",
    "            Y_list.append(0)\n",
    "    return Y_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "ca86b71c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Claxton hunting first major medal', \"British hurdler Sarah Claxton is confident she can win her first major medal at next month's European Indoor Championships in Madrid\", 'The 25-year-old has already smashed the British record over 60m hurdles twice this season, setting a new mark of 7', '96 seconds to win the AAAs title', 'I am quite confident, said Claxton', 'But I take each race as it comes', 'As long as I keep up my training but not do too much I think there is a chance of a medal', 'Claxton has won the national 60m hurdles title for the past three years but has struggled to translate her domestic success to the international stage', 'Now, the Scotland-born athlete owns the equal fifth-fastest time in the world this year', \"And at last week's Birmingham Grand Prix, Claxton left European medal favourite Russian Irina Shevchenko trailing in sixth spot\", 'For the first time, Claxton has only been preparing for a campaign over the hurdles - which could explain her leap in form', 'In previous seasons, the 25-year-old also contested the long jump but since moving from Colchester to London she has re-focused her attentions', 'Claxton will see if her new training regime pays dividends at the European Indoors which take place on 5-6 March']\n",
      "['For the first time, Claxton has only been preparing for a campaign over the hurdles - which could explain her leap in form', 'Claxton has won the national 60m hurdles title for the past three years but has struggled to translate her domestic success to the international stage', \"British hurdler Sarah Claxton is confident she can win her first major medal at next month's European Indoor Championships in Madrid\", 'Claxton will see if her new training regime pays dividends at the European Indoors which take place on 5-6 March', 'I am quite confident, said Claxton']\n",
      "13\n",
      "5\n",
      "British hurdler Sarah Claxton is confident she can win her first major medal at next month's European Indoor Championships in Madrid\n",
      "I am quite confident, said Claxton\n",
      "Claxton has won the national 60m hurdles title for the past three years but has struggled to translate her domestic success to the international stage\n",
      "For the first time, Claxton has only been preparing for a campaign over the hurdles - which could explain her leap in form\n",
      "Claxton will see if her new training regime pays dividends at the European Indoors which take place on 5-6 March\n",
      "[0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1]\n"
     ]
    }
   ],
   "source": [
    "Y = generate_Y_labels(original, summarized)\n",
    "print(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "cafa7316",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_X_labels(preprocessed_artcile):\n",
    "    sentence_length_feature = sentence_length(preprocessed_artcile)\n",
    "    \n",
    "    article_modified = convert_list_to_string(article_preprocessed)\n",
    "    tf_idf_matrix = calculate_TF_IDF(article_modified)\n",
    "    score = []\n",
    "    for index, line in enumerate(tf_idf_matrix):\n",
    "#         print(line)\n",
    "#         print('at')\n",
    "#         print(index)\n",
    "        score.append(np.sum(line))\n",
    "    matrix = np.column_stack((sentence_length_feature, score))\n",
    "    matrix = matrix[:len(matrix)-1]\n",
    "    return matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "a75b733f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['claxton', 'hunt', 'first', 'major', 'medal']\n",
      "['british', 'hurdler', 'sarah', 'claxton', 'confid', 'win', 'first', 'major', 'medal', 'next', \"month'\", 'european', 'indoor', 'championship', 'madrid']\n",
      "['the', '25-year-old', 'alreadi', 'smash', 'british', 'record', '60m', 'hurdl', 'twice', 'season,', 'set', 'new', 'mark', '7']\n",
      "['96', 'second', 'win', 'aaa', 'titl']\n",
      "['\"i', 'quit', 'confident,\"', 'said', 'claxton']\n",
      "['\"but', 'i', 'take', 'race', 'come']\n",
      "['\"a', 'long', 'i', 'keep', 'train', 'much', 'i', 'think', 'chanc', 'medal']\n",
      "['claxton', 'nation', '60m', 'hurdl', 'titl', 'past', 'three', 'year', 'struggl', 'translat', 'domest', 'success', 'intern', 'stage']\n",
      "['now,', 'scotland-born', 'athlet', 'own', 'equal', 'fifth-fastest', 'time', 'world', 'year']\n",
      "['and', 'last', \"week'\", 'birmingham', 'grand', 'prix,', 'claxton', 'left', 'european', 'medal', 'favourit', 'russian', 'irina', 'shevchenko', 'trail', 'sixth', 'spot']\n",
      "['for', 'first', 'time,', 'claxton', 'prepar', 'campaign', 'hurdl', 'could', 'explain', 'leap', 'form']\n",
      "['in', 'previou', 'seasons,', '25-year-old', 'also', 'contest', 'long', 'jump', 'sinc', 'move', 'colchest', 'london', 're-focus', 'attent']\n",
      "['claxton', 'see', 'new', 'train', 'regim', 'pay', 'dividend', 'european', 'indoor', 'take', 'place', '5-6', 'march']\n",
      "[]\n",
      "[[0.29411765 2.1925485 ]\n",
      " [0.88235294 3.82819379]\n",
      " [0.82352941 3.85198754]\n",
      " [0.29411765 2.2306669 ]\n",
      " [0.29411765 1.95123377]\n",
      " [0.29411765 1.99637852]\n",
      " [0.58823529 2.62763431]\n",
      " [0.82352941 3.69742079]\n",
      " [0.52941176 3.30152319]\n",
      " [1.         4.08286008]\n",
      " [0.64705882 3.27426007]\n",
      " [0.82352941 4.10771955]\n",
      " [0.76470588 3.42691045]]\n"
     ]
    }
   ],
   "source": [
    "X = generate_X_labels(article_preprocessed)\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "31ffa1dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13\n",
      "13\n",
      "[0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1]\n",
      "[[0.29411765 2.1925485 ]\n",
      " [0.88235294 3.82819379]\n",
      " [0.82352941 3.85198754]\n",
      " [0.29411765 2.2306669 ]\n",
      " [0.29411765 1.95123377]\n",
      " [0.29411765 1.99637852]\n",
      " [0.58823529 2.62763431]\n",
      " [0.82352941 3.69742079]\n",
      " [0.52941176 3.30152319]\n",
      " [1.         4.08286008]\n",
      " [0.64705882 3.27426007]\n",
      " [0.82352941 4.10771955]\n",
      " [0.76470588 3.42691045]]\n"
     ]
    }
   ],
   "source": [
    "m = len(Y)  # training set size\n",
    "m2 = len(X)\n",
    "print(m)\n",
    "print(m2)\n",
    "nn_input_dim = 2  # input layer dimensionality (we have two input features)\n",
    "nn_output_dim = 1  # output layer dimensionality (we have one output)\n",
    "\n",
    "# Gradient descent parameters\n",
    "alpha = 0.2  # learning rate for gradient descent\n",
    "print(Y)\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "0e60ac33",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    # TODO 1: Compute the sigmoid function at the given x (~1 line)\n",
    "    # For example: sigmoid(2) should compute the value of sigmoid function at x = 2.\n",
    "    # Hint: Use np.exp instead of math.exp to allow for vectorization.\n",
    "    #----------------------------------------------------------------------------------------------\n",
    "    sig = (1/(1+np.exp(-x)))\n",
    "    #----------------------------------------------------------------------------------------------\n",
    "    \n",
    "    return sig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "20facec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(nn_hdim, num_passes=20000, print_loss=False):\n",
    "    \n",
    "    # This function learns parameters for the neural network and returns the model.\n",
    "    # - nn_hdim: Number of nodes in the hidden layer\n",
    "    # - num_passes: Number of iterations (epochs) through the training data for gradient descent\n",
    "    # - print_loss: If True, print the loss every 1000 iterations\n",
    "\n",
    "    # Initialize the parameters to random values. We need to learn these at the end.\n",
    "    np.random.seed(0)\n",
    "    W1 = np.random.randn(nn_hdim, nn_input_dim) / np.sqrt(nn_input_dim)\n",
    "    b1 = np.zeros((nn_hdim, 1))\n",
    "    W2 = np.random.randn(nn_output_dim, nn_hdim) / np.sqrt(nn_hdim)\n",
    "    b2 = np.zeros((nn_output_dim, 1))\n",
    "\n",
    "    # This is what we return at the end\n",
    "    model = {}\n",
    "\n",
    "    # Batch Gradient descent (We accumulate the loss for each training point before updating the weights)\n",
    "    # For each iteration:\n",
    "    for i in range(0, num_passes):\n",
    "        DW1 = 0\n",
    "        DW2 = 0\n",
    "        Db1 = 0\n",
    "        Db2 = 0\n",
    "        cost = 0\n",
    "        # Loop on every training example...\n",
    "        for j in range(0, m):\n",
    "            a0 = X[j, :].reshape(-1, 1)  # Every training example is a column vector.\n",
    "            y = Y[j]\n",
    "            \n",
    "            # TODO 2: Apply forward propagation on every training example a0 (a column vector 2x1) with its\n",
    "            # corresponding label y. It is required to compute z1, a1, z2, and a2\n",
    "            #----------------------------------------------------------------------------------------------\n",
    "            # Forward propagation\n",
    "            z1 = np.dot(W1 , a0 )+ b1\n",
    "            a1 = np.tanh(z1)\n",
    "            z2 = np.dot(W2 , a1) + b2\n",
    "            a2 = sigmoid(z2)\n",
    "            #----------------------------------------------------------------------------------------------\n",
    "\n",
    "            # TODO 3: Compute the cost/loss function for every training example (Hint: use np.log)\n",
    "            # ---------------------------------------------------------------------------------------------\n",
    "            cost_j = -1 * ((np.log(a2) * y + (1-y)* np.log(1-a2)))\n",
    "            # ---------------------------------------------------------------------------------------------\n",
    "\n",
    "            # TODO 4: Derive the equations of backpropagation to find dW2, db2, dW1, and db1.\n",
    "            # Hint: Check the dimensions at each step. \n",
    "            # Hint: For element-wise multiplication use *, for matrix multiplication use @\n",
    "            # Example: y = A * B performs element wise multiplication \n",
    "            #          y = A @ B performs matrix multiplication\n",
    "            # ---------------------------------------------------------------------------------------------\n",
    "            da2 =  ( -y/a2  + (1-y)/(1-a2) )\n",
    "            dz2 =  da2 * a2 * ( 1 - a2)\n",
    "            dW2 = np.dot(dz2 , a1.T)\n",
    "            db2 = dz2\n",
    "\n",
    "            da1 =  np.dot(dz2,W2).T\n",
    "            dz1 = np.multiply(da1 , 1 - np.square(a1) )\n",
    "            dW1 = np.dot(dz1 , a0.T )\n",
    "            db1 = dz1\n",
    "            # ---------------------------------------------------------------------------------------------\n",
    "            \n",
    "            # Accumulating the sum of dW1, db1, dW2, db2 and cost_j into the variables DW1, Db1, DW2, Db2 and cost\n",
    "            # for all training set. \n",
    "            DW1 += dW1\n",
    "            DW2 += dW2\n",
    "            Db2 += db2\n",
    "            Db1 += db1\n",
    "            cost += cost_j\n",
    "        \n",
    "        # Averaging DW1, DW2, Db1, Db2 and cost over the m training examples. \n",
    "        DW1 /= m\n",
    "        DW2 /= m\n",
    "        Db1 /= m\n",
    "        Db2 /= m\n",
    "        cost /= m\n",
    "\n",
    "        # TODO 5: Perform the gradient descent parameter update.\n",
    "        # ---------------------------------------------------------------------------------------------------\n",
    "        # Gradient descent parameter update\n",
    "        W1 -= alpha * DW1\n",
    "        b1 -= alpha * Db1\n",
    "        W2 -= alpha * DW2\n",
    "        b2 -= alpha * Db2\n",
    "        # ---------------------------------------------------------------------------------------------------\n",
    "\n",
    "        # Assign new parameters to the model\n",
    "        model = {'W1': W1, 'b1': b1, 'W2': W2, 'b2': b2}\n",
    "\n",
    "        # Optionally print the loss.\n",
    "        # This is expensive because it uses the whole dataset, so we don't want to do it too often.\n",
    "        if print_loss and i % 1000 == 0:\n",
    "            print(\"Loss after iteration %i: %f\" % (i, cost))\n",
    "    print(model)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "0664206e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to predict an output (0 or 1)\n",
    "def predict(model, x):\n",
    "    W1, b1, W2, b2 = model['W1'], model['b1'], model['W2'], model['b2']\n",
    "    a0 = x.T\n",
    "    \n",
    "    # TODO 6 (aka TODO 2): Apply forward propagation on every test example a0 (a column vector 2x1) with its\n",
    "    #  corresponding label y. It is required to compute z1, a1, z2, and a2  (SAME AS TODO2).\n",
    "    # -----------------------------------------------------------------------------------------------\n",
    "    z1 = np.dot(W1 , a0) + b1\n",
    "    a1 = sigmoid(z1)\n",
    "    z2 = np.dot(W2 , a1) + b2\n",
    "    a2 = sigmoid(z2)\n",
    "    # ------------------------------------------------------------------------------------------------\n",
    "    # Applying a threshold of 0.5 (i.e. predictions greater than 0.5 are mapped to 1, and 0 otherwise)\n",
    "    prediction = np.round(a2)\n",
    "    \n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "7508490d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after iteration 0: 0.684393\n",
      "Loss after iteration 1000: 0.614555\n",
      "Loss after iteration 2000: 0.596470\n",
      "Loss after iteration 3000: 0.574862\n",
      "Loss after iteration 4000: 0.548112\n",
      "Loss after iteration 5000: 0.509054\n",
      "Loss after iteration 6000: 0.469818\n",
      "Loss after iteration 7000: 0.443109\n",
      "Loss after iteration 8000: 0.409340\n",
      "Loss after iteration 9000: 0.316174\n",
      "Loss after iteration 10000: 0.254303\n",
      "{'W1': array([[12.26954788, -3.45243096],\n",
      "       [ 0.5801395 ,  0.74633741],\n",
      "       [ 1.36176148, -4.17164096],\n",
      "       [ 0.16700643, -0.52786444],\n",
      "       [ 0.63121089,  1.02068698],\n",
      "       [ 0.87423084,  0.96460447],\n",
      "       [-0.24798193, -1.19908236],\n",
      "       [ 0.95918156, -2.93361678]]), 'b1': array([[ 4.48743384],\n",
      "       [-0.52572212],\n",
      "       [15.03638251],\n",
      "       [ 0.45146368],\n",
      "       [-2.00637842],\n",
      "       [-2.01112914],\n",
      "       [ 2.25139129],\n",
      "       [ 7.87686656]]), 'W2': array([[ 6.4886588 , -1.19787487,  3.58297149,  0.85084144, -2.63104263,\n",
      "        -2.19928309,  2.62615517, -5.27983905]]), 'b2': array([[-0.88555368]])}\n"
     ]
    }
   ],
   "source": [
    "model = build_model(nn_hdim=8, num_passes=10001, print_loss=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b910c87",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
